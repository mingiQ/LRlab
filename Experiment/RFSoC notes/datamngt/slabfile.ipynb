{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlabFile(h5py.File):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        h5py.File.__init__(self, *args, **kwargs)\n",
    "        # self.attrs[\"_script\"] = open(sys.argv[0], 'r').read()\n",
    "        # if self.mode is not 'r':\n",
    "        # self.attrs[\"_script\"] = get_script()\n",
    "        # if not read-only or existing then save the script into the .h5\n",
    "        # Maybe should take this automatic feature out and just do it when you want to\n",
    "        # Automatic feature taken out. Caused more trouble than convenience. Ge Yang\n",
    "        # if 'save_script' in kwargs:\n",
    "        # save_script = kwargs['save_script']\n",
    "        # else:\n",
    "        # save_script = True\n",
    "        # if (self.mode is not 'r') and (\"_script\" not in self.attrs) and (save_script):\n",
    "        # self.save_script()\n",
    "        self.flush()\n",
    "\n",
    "    # Methods for proxy use    \n",
    "    def _my_ds_from_path(self, dspath):\n",
    "        \"\"\"returns the object (dataset or group) specified by dspath\"\"\"\n",
    "        branch = self\n",
    "        for ds in dspath:\n",
    "            branch = branch[ds]\n",
    "        return branch\n",
    "\n",
    "    def _my_assign_dset(self, dspath, ds, val):\n",
    "        print('assigning', ds, val)\n",
    "        branch = self._my_ds_from_path(dspath)\n",
    "        branch[ds] = val\n",
    "\n",
    "    def _get_dset_array(self, dspath):\n",
    "        \"\"\"returns a pickle-safe array for the branch specified by dspath\"\"\"\n",
    "        branch = self._my_ds_from_path(dspath)\n",
    "        if isinstance(branch, h5py.Group):\n",
    "            return 'group'\n",
    "        else:\n",
    "            return (H5Array(branch), dict(branch.attrs))\n",
    "\n",
    "    def _get_attrs(self, dspath):\n",
    "        branch = self._my_ds_from_path(dspath)\n",
    "        return dict(branch.attrs)\n",
    "\n",
    "    def _set_attr(self, dspath, item, value):\n",
    "        branch = self._my_ds_from_path(dspath)\n",
    "        branch.attrs[item] = value\n",
    "\n",
    "    def _call_with_path(self, dspath, method, args, kwargs):\n",
    "        branch = self._my_ds_from_path(dspath)\n",
    "        return getattr(branch, method)(*args, **kwargs)\n",
    "\n",
    "    def _ping(self):\n",
    "        return 'OK'\n",
    "\n",
    "    def set_range(self, dataset, xmin, xmax, ymin=None, ymax=None):\n",
    "        if ymin is not None and ymax is not None:\n",
    "            dataset.attrs[\"_axes\"] = ((xmin, xmax), (ymin, ymax))\n",
    "        else:\n",
    "            dataset.attrs[\"_axes\"] = (xmin, xmax)\n",
    "\n",
    "    def set_labels(self, dataset, x_lab, y_lab, z_lab=None):\n",
    "        if z_lab is not None:\n",
    "            dataset.attrs[\"_axes_labels\"] = (x_lab, y_lab, z_lab)\n",
    "        else:\n",
    "            dataset.attrs[\"_axes_labels\"] = (x_lab, y_lab)\n",
    "\n",
    "    def append_line(self, dataset, line, axis=0):\n",
    "        if isinstance(dataset,str): dataset=str(dataset)\n",
    "        if isinstance(dataset, str):\n",
    "            try:\n",
    "                dataset = self[dataset]\n",
    "            except:\n",
    "                shape, maxshape = (0, len(line)), (None, len(line))\n",
    "                if axis == 1:\n",
    "                    shape, maxshape = (shape[1], shape[0]), (maxshape[1], maxshape[0])\n",
    "                self.create_dataset(dataset, shape=shape, maxshape=maxshape, dtype='float64')\n",
    "                dataset = self[dataset]\n",
    "        shape = list(dataset.shape)\n",
    "        shape[axis] = shape[axis] + 1\n",
    "        dataset.resize(shape)\n",
    "        if axis == 0:\n",
    "            dataset[-1, :] = line\n",
    "        else:\n",
    "            dataset[:, -1] = line\n",
    "        self.flush()\n",
    "\n",
    "    def append_pt(self, dataset, pt):\n",
    "        if isinstance(dataset,str):\n",
    "            dataset=str(dataset)\n",
    "        if isinstance(dataset, str) :\n",
    "            try:\n",
    "                dataset = self[dataset]\n",
    "            except:\n",
    "                self.create_dataset(dataset, shape=(0,), maxshape=(None,), dtype='float64')\n",
    "                dataset = self[dataset]\n",
    "        shape = list(dataset.shape)\n",
    "        shape[0] = shape[0] + 1\n",
    "        dataset.resize(shape)\n",
    "        dataset[-1] = pt\n",
    "        self.flush()\n",
    "\n",
    "    def append_dset_pt(self, dataset, pt):\n",
    "        shape = dataset.shape[0]\n",
    "        shape = shape + 1\n",
    "        dataset.resize((shape, ))\n",
    "        dataset[-1] = pt\n",
    "        dataset.flush()\n",
    "\n",
    "    def note(self, note):\n",
    "        \"\"\"Add a timestamped note to HDF file, in a dataset called 'notes'\"\"\"\n",
    "        ts = datetime.datetime.now()\n",
    "        try:\n",
    "            ds = self['notes']\n",
    "        except:\n",
    "            ds = self.create_dataset('notes', (0,), maxshape=(None,), dtype=h5py.new_vlen(str))\n",
    "\n",
    "        shape = list(ds.shape)\n",
    "        shape[0] = shape[0] + 1\n",
    "        ds.resize(shape)\n",
    "        ds[-1] = str(ts) + ' -- ' + note\n",
    "        self.flush()\n",
    "\n",
    "    def get_notes(self, one_string=False, print_notes=False):\n",
    "        \"\"\"Returns notes embedded in HDF file if present.\n",
    "        @param one_string=False if True concatenates them all together\n",
    "        @param print_notes=False if True prints all the notes to stdout\n",
    "        \"\"\"\n",
    "        try:\n",
    "            notes = list(self['notes'])\n",
    "        except:\n",
    "            notes = []\n",
    "        if print_notes:\n",
    "            print('\\n'.join(notes))\n",
    "        if one_string:\n",
    "            notes = '\\n'.join(notes)\n",
    "        return notes\n",
    "\n",
    "    def add_data(self, f, key, data):\n",
    "        data = np.array(data)\n",
    "        try:\n",
    "            f.create_dataset(key, shape=data.shape,\n",
    "                             maxshape=tuple([None] * len(data.shape)),\n",
    "                             dtype=str(data.dtype))\n",
    "        except RuntimeError:\n",
    "            del f[key]\n",
    "            f.create_dataset(key, shape=data.shape,\n",
    "                             maxshape=tuple([None] * len(data.shape)),\n",
    "                             dtype=str(data.dtype))\n",
    "        f[key][...] = data\n",
    "\n",
    "    def append_data(self, f, key, data, forceInit=False):\n",
    "        \"\"\"\n",
    "        the main difference between append_pt and append is thta\n",
    "        append takes care of highier dimensional data, but not append_pt\n",
    "        \"\"\"\n",
    "\n",
    "        data = np.array(data)\n",
    "        try:\n",
    "            f.create_dataset(key, shape=tuple([1] + list(data.shape)),\n",
    "                             maxshape=tuple([None] * (len(data.shape) + 1)),\n",
    "                             dtype=str(data.dtype))\n",
    "        except RuntimeError:\n",
    "            if forceInit == True:\n",
    "                del f[key]\n",
    "                f.create_dataset(key, shape=tuple([1] + list(data.shape)),\n",
    "                                 maxshape=tuple([None] * (len(data.shape) + 1)),\n",
    "                                 dtype=str(data.dtype))\n",
    "            dataset = f[key]\n",
    "            Shape = list(dataset.shape)\n",
    "            Shape[0] = Shape[0] + 1\n",
    "            dataset.resize(Shape)\n",
    "\n",
    "        dataset = f[key]\n",
    "        try:\n",
    "            dataset[-1, :] = data\n",
    "        except TypeError:\n",
    "            dataset[-1] = data\n",
    "            # Usage require strictly same dimensionality for all data appended.\n",
    "            # currently I don't have it setup to return a good exception, but should\n",
    "\n",
    "    def add(self, key, data):\n",
    "        self.add_data(self, key, data)\n",
    "\n",
    "    def append(self, dataset, pt):\n",
    "        self.append_data(self, dataset, pt)\n",
    "\n",
    "    # def save_script(self, name=\"_script\"):\n",
    "    # self.attrs[name] = get_script()\n",
    "    def save_dict(self, dict, group='/'):\n",
    "        if group not in self:\n",
    "            self.create_group(group)\n",
    "        for k in list(dict.keys()):\n",
    "            self[group].attrs[k] = dict[k]\n",
    "\n",
    "    def get_dict(self, group='/'):\n",
    "        d = {}\n",
    "        for k in list(self[group].attrs.keys()):\n",
    "            d[k] = self[group].attrs[k]\n",
    "        return d\n",
    "\n",
    "    get_attrs = get_dict\n",
    "    save_attrs = save_dict\n",
    "\n",
    "\n",
    "    def save_settings(self, dic, group='settings'):\n",
    "        self.save_dict(dic, group)\n",
    "\n",
    "    def load_settings(self, group='settings'):\n",
    "        return self.get_dict(group)\n",
    "\n",
    "    def load_config(self):\n",
    "        if 'config' in list(self.attrs.keys()):\n",
    "            return AttrDict(json.loads(self.attrs['config']))\n",
    "        else:\n",
    "            return None\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
